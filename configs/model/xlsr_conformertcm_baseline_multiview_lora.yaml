_target_: src.models.xlsr_conformertcm_baseline_mdt_lora_module.XLSRConformerTCMLoraLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.000001
  weight_decay: 0.0001

scheduler: null

args:
  conformer:
    emb_size: 144
    heads: 4
    kernel_size: 31
    n_encoders: 4
    type: "conv" # conv_res2net, conv_seblock, conv_res2net_seblock
    pooling: "first"
  lora:
    r: 16
    target_modules: ["q_proj", "v_proj", "k_proj"]
    modules_to_save: ""
    lora_dropout: 0.0
    lora_alpha: 8


use_lora: true
ssl_pretrained_path: ${oc.env:XLSR_PRETRAINED_MODEL_PATH}
base_line_ft_path: ${oc.env:BASE_LINE_FT_PATH}
cross_entropy_weight: [0.1, 0.9] # weight for cross entropy loss 0.1 for spoof and 0.9 for bonafide
# compile model for faster training with pytorch 2.0
compile: false
