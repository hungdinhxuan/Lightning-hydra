# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: asvspoof_multiview
  - override /model: xlsr_aasist_multiview
  - override /callbacks: none
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 12345

trainer:
  min_epochs: 20
  max_epochs: 30
  gradient_clip_val: 0.5
  accelerator: cuda

model:
  optimizer:
    lr: 0.000001
  net:
    d_args:
      first_conv: 128
      filts: [70, [1, 32], [32, 32], [32, 64], [64, 64]]
      gat_dims: [64, 32]
      pool_ratios: [0.5, 0.7, 0.5, 0.5]
      temperatures: [2.0, 2.0, 100.0, 100.0]
  compile: false

data:
  batch_size: 8
  num_workers: 8

logger:
  wandb:
    tags: ${tags}
    group: "asvspoof_multiview"
  aim:
    experiment: "asvspoof_multiview"

# task name, determines output directory path
task_name: "eval"

# tags to help you identify your experiments
# you can overwrite this in experiment configs
# overwrite from command line with `python train.py tags="[first_tag, second_tag]"`
# appending lists from command line is currently not supported :(
# https://github.com/facebookresearch/hydra/issues/1547
tags: ["dev"]

# set False to skip model training
train: False

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True

