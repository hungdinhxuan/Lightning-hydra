# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: normal_largecorpus_for_asvspoof5
  - override /model: v2/xlsr_conformertcm_lora
  - override /callbacks: default_lora_loss_earlystop_logger
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["normal_largecorpus_for_asvspoof5", "xlsr_conformertcm_lora"]

seed: 1234

trainer:
  max_epochs: 100
  gradient_clip_val: 0.0
  accelerator: cuda

model:
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.00001 # 1e-5
    weight_decay: 0.0001
  net: null
  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    _partial_: true
    milestones:
      - 5
      - 15
    gamma : 0.1 # Multiplicative factor of learning rate decay.

  cross_entropy_weight: [0.7, 0.3] # Balanced weights for cross entropy loss
  args:
    adapter:
      r: 8
      target_modules: ["q_proj", "v_proj", "k_proj", "out_proj", "fc1", "fc2", "final_proj", "LL", "qkv", "proj", "ht_proj"] # All dense layers (, "fc1", "fc2", "final_proj", "LL", "qkv", "proj", "ht_proj")
      modules_to_save:  [] # conformer qkv
      lora_dropout: 0.1
      lora_alpha: 16
      init_lora_weights: "gaussian"
  
data:
  batch_size: 16
  num_workers: 8
  pin_memory: true
  data_dir: ${oc.env:NOISE_DATASET_PATH}

  args:
    protocol_path: ${oc.env:NOISE_DATASET_PROTOCOL}
    augmentation_methods: ["gaussian_v1", "none"]
    padding_type: repeat
    random_start: True
    view_padding_configs:
      '1':
        padding_type: repeat
        random_start: True
      '2':
        padding_type: repeat
        random_start: True
      '3':
        padding_type: repeat
        random_start: True
      '4':
        padding_type: repeat
        random_start: True


logger:
  wandb:
    tags: ${tags}
    group: "normal_largecorpus_for_asvspoof5"
  aim:
    experiment: "normal_largecorpus_for_asvspoof5"
