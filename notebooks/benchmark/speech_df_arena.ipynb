{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac26086d",
   "metadata": {},
   "source": [
    "## This notebook is designed to update protocol.txt files from following datasets to standardize the format with [huggingface](https://huggingface.co/spaces/Speech-Arena-2025/Speech-DF-Arena) datasets\n",
    "\n",
    "List of datasets:\n",
    "- ASVSpoof 2019 eval \n",
    "- ASVSpoof 2021 LA eval\n",
    "- ASVSpoof 2021 DF eval\n",
    "- ASVSpoof 2024 eval\n",
    "- SONAR\n",
    "- Codecfake\n",
    "- Fake or Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644369be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a159562",
   "metadata": {},
   "source": [
    "### ASVSpoof 2019 eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28746f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71232</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>bonafide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71233</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71234</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71235</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>bonafide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71236</th>\n",
       "      <td>/data/data/AntiSpoofing-Datasets/ASVSpoof2019_...</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     utt     label\n",
       "0      /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "1      /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "2      /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "3      /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "4      /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "...                                                  ...       ...\n",
       "71232  /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...  bonafide\n",
       "71233  /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "71234  /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "71235  /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...  bonafide\n",
       "71236  /data/data/AntiSpoofing-Datasets/ASVSpoof2019_...     spoof\n",
       "\n",
       "[71237 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_asv19 = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"asvspoof_2019.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_asv19.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "hf_asv19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "188af567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utt</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flac/LA_E_8877452.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flac/LA_E_6828287.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flac/LA_E_6977360.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flac/LA_E_5932896.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flac/LA_E_5849185.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>bonafide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71231</th>\n",
       "      <td>flac/LA_E_1665632.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>bonafide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71232</th>\n",
       "      <td>flac/LA_E_5085671.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71233</th>\n",
       "      <td>flac/LA_E_4926022.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71234</th>\n",
       "      <td>flac/LA_E_2894498.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>bonafide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71235</th>\n",
       "      <td>flac/LA_E_4689563.flac</td>\n",
       "      <td>eval</td>\n",
       "      <td>spoof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71236 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          utt subset     label\n",
       "0      flac/LA_E_8877452.flac   eval     spoof\n",
       "1      flac/LA_E_6828287.flac   eval     spoof\n",
       "2      flac/LA_E_6977360.flac   eval     spoof\n",
       "3      flac/LA_E_5932896.flac   eval     spoof\n",
       "4      flac/LA_E_5849185.flac   eval  bonafide\n",
       "...                       ...    ...       ...\n",
       "71231  flac/LA_E_1665632.flac   eval  bonafide\n",
       "71232  flac/LA_E_5085671.flac   eval     spoof\n",
       "71233  flac/LA_E_4926022.flac   eval     spoof\n",
       "71234  flac/LA_E_2894498.flac   eval  bonafide\n",
       "71235  flac/LA_E_4689563.flac   eval     spoof\n",
       "\n",
       "[71236 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_asv19 = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/ASVspoof2019_LA_eval/protocol.txt\", sep=\" \", header=None)\n",
    "current_asv19.columns = [\"utt\", \"subset\", \"label\"]\n",
    "current_asv19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d8a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing lines in current_asv19: {'LA_E_2834763.flac'}\n",
      "Updated current_asv19 shape: (71237, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'utt' column exists in both DataFrames\n",
    "if 'utt' not in current_asv19.columns or 'utt' not in hf_asv19.columns:\n",
    "    raise ValueError(\"Column 'utt' not found in one or both DataFrames\")\n",
    "\n",
    "# Extract the final component (filename) from 'utt' column\n",
    "current_asv19['utt'] = current_asv19['utt'].apply(lambda x: x.split('/')[-1] if isinstance(x, str) else x)\n",
    "hf_asv19['utt'] = hf_asv19['utt'].apply(lambda x: x.split('/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Check lines missing from current_asv19\n",
    "missing_lines = set(hf_asv19['utt']) - set(current_asv19['utt'])\n",
    "print(f\"Missing lines in current_asv19: {missing_lines}\")\n",
    "\n",
    "# Add missing lines to current_asv19\n",
    "if missing_lines:\n",
    "    missing_rows = hf_asv19[hf_asv19['utt'].isin(missing_lines)]\n",
    "    current_asv19 = pd.concat([current_asv19, missing_rows], ignore_index=True)\n",
    "else:\n",
    "    print(\"No missing lines to add\")\n",
    "\n",
    "# Optional: Verify the updated DataFrame\n",
    "print(f\"Updated current_asv19 shape: {current_asv19.shape}\")\n",
    "\n",
    "# Manually add the missing lines to current_asv19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a79de6",
   "metadata": {},
   "source": [
    "### ASVSpoof 2021 LA eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_asvla21 = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"asvspoof_2021_la.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_asvla21.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "hf_asvla21['utt'] = hf_asvla21['utt'].apply(lambda x: x.split('/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Add column 'subset' to hf_asvla21\n",
    "hf_asvla21['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_asvla21 = hf_asvla21[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "# export the DataFrame to a CSV file\n",
    "hf_asvla21.to_csv(\"asvspoof_2021_la.txt\", sep=\" \", index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c07581",
   "metadata": {},
   "source": [
    "### ASVSpoof 2021 DF eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "070ea320",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_asvdf21 = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"asvspoof_2021_df.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_asvdf21.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "hf_asvdf21['utt'] = hf_asvdf21['utt'].apply(lambda x: x.split('/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Add column 'subset' to hf_asvdf21\n",
    "hf_asvdf21['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_asvdf21 = hf_asvdf21[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "# export the DataFrame to a CSV file\n",
    "hf_asvdf21.to_csv(\"asvspoof_2021_df.txt\", sep=\" \", index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf0b6e",
   "metadata": {},
   "source": [
    "### ASVSpoof 2024 eval\n",
    "correct "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34986c",
   "metadata": {},
   "source": [
    "### SONAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b5d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_sonar = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"sonar.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_sonar.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "# Add column 'subset' to hf_asvdf21\n",
    "hf_sonar['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_sonar = hf_sonar[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "hf_sonar['utt'] = hf_sonar['utt'].apply(lambda x: x.split('/data/data/AntiSpoofing-Datasets/SONAR/SONAR_dataset/')[-1] if isinstance(x, str) else x)\n",
    "hf_sonar.to_csv(\"sonar.txt\", sep=\" \", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe984981",
   "metadata": {},
   "source": [
    "### Codecfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4526c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_codecfake = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"codecfake.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_codecfake.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "hf_codecfake['utt'] = hf_codecfake['utt'].apply(lambda x: x.split('/data/data/AntiSpoofing-Datasets/CodecFake/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Add column 'subset' to hf_asvdf21\n",
    "hf_codecfake['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_codecfake = hf_codecfake[[\"utt\", \"subset\", \"label\"]]\n",
    "            \n",
    "hf_codecfake.to_csv(\"codecfake.txt\", sep=\" \", index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b364724c",
   "metadata": {},
   "source": [
    "### Fake or Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd13f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_fake_or_real = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"fake_or_real.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_fake_or_real.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "hf_fake_or_real['utt'] = hf_fake_or_real['utt'].apply(lambda x: x.split('/data/data/AntiSpoofing-Datasets/for-norm/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Add column 'subset' to hf_asvdf21\n",
    "hf_fake_or_real['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_fake_or_real = hf_fake_or_real[[\"utt\", \"subset\", \"label\"]]\n",
    "     \n",
    "hf_fake_or_real.to_csv(\"fake_or_real.txt\", sep=\" \", index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c58468",
   "metadata": {},
   "source": [
    "# In the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d4527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_protocol_dir = \"/nvme1/hungdx/Lightning-hydra/data/speech_df_arena/protocol_files\"\n",
    "hf_in_the_wild = pd.read_csv(\n",
    "    os.path.join(hf_protocol_dir, \"in_the_wild.csv\"),\n",
    "    sep=\",\")\n",
    "# change the column names to be more readable\n",
    "hf_in_the_wild.columns = [\n",
    "    \"utt\", \"label\"]\n",
    "\n",
    "hf_in_the_wild['utt'] = hf_in_the_wild['utt'].apply(lambda x: x.split('/data/data/AntiSpoofing-Datasets/In_Wild/')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Add column 'subset' to hf_asvdf21\n",
    "hf_in_the_wild['subset'] = 'eval'\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "hf_in_the_wild = hf_in_the_wild[[\"utt\", \"subset\", \"label\"]]\n",
    "     \n",
    "hf_in_the_wild.to_csv(\"in_the_wild.txt\", sep=\" \", index=False, header=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
