{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950aef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c773e41",
   "metadata": {},
   "source": [
    "# ASVspoof2019_LA_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab6b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3d29e",
   "metadata": {},
   "source": [
    "# ASVspoof2021_LA_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e06cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_metadata = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/notebooks/asvspoof-challenge-2021/eval-package/keys/LA/CM/trial_metadata.txt\", sep=\" \", header=None)\n",
    "# only keep column 1th and 5th\n",
    "\n",
    "trial_metadata = trial_metadata[[1, 5]]\n",
    "\n",
    "# adding column subset with value is eval to trial_metadata\n",
    "\n",
    "trial_metadata.columns = [\"utt\", \"label\"]\n",
    "\n",
    "trial_metadata[\"subset\"] = \"eval\"\n",
    "\n",
    "# Add flac extension to utt\n",
    "trial_metadata[\"utt\"] = trial_metadata[\"utt\"].apply(lambda x: os.path.splitext(x)[0] + \".flac\")\n",
    "\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "trial_metadata = trial_metadata[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "# export to protocol.txt\n",
    "\n",
    "trial_metadata.to_csv(\"asvspoof2021_la_eval_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbe0ff",
   "metadata": {},
   "source": [
    "# ASVspoof2021_DF_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e783f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_metadata = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/notebooks/asvspoof-challenge-2021/eval-package/keys/DF/CM/trial_metadata.txt\", sep=\" \", header=None)\n",
    "# only keep column 1th and 5th\n",
    "\n",
    "trial_metadata = trial_metadata[[1, 5]]\n",
    "\n",
    "# adding column subset with value is eval to trial_metadata\n",
    "\n",
    "trial_metadata.columns = [\"utt\", \"label\"]\n",
    "\n",
    "trial_metadata[\"subset\"] = \"eval\"\n",
    "\n",
    "trial_metadata[\"utt\"] = trial_metadata[\"utt\"].apply(lambda x: os.path.splitext(x)[0] + \".flac\")\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "trial_metadata = trial_metadata[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "# export to protocol.txt\n",
    "\n",
    "trial_metadata.to_csv(\"asvspoof2021_df_eval_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65ed8c",
   "metadata": {},
   "source": [
    "# ASVSpoof2024-Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5904e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ce1bc",
   "metadata": {},
   "source": [
    "# ASVSpoof2024-Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de1062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_metadata = pd.read_csv(\"/data/ASVspoof5/ASVspoof5.eval.track_1.tsv\", sep=\" \", header=None)\n",
    "\n",
    "# only keep column 1th and 8th\n",
    "\n",
    "trial_metadata = trial_metadata[[1, 8]]\n",
    "\n",
    "# adding column subset with value is eval to trial_metadata\n",
    "\n",
    "trial_metadata.columns = [\"utt\", \"label\"]\n",
    "\n",
    "trial_metadata[\"subset\"] = \"eval\"\n",
    "\n",
    "trial_metadata[\"utt\"] = trial_metadata[\"utt\"].apply(lambda x: os.path.splitext(x)[0] + \".flac\")\n",
    "\n",
    "# change column order to [utt, subset, label]\n",
    "trial_metadata = trial_metadata[[\"utt\", \"subset\", \"label\"]]\n",
    "\n",
    "# export to protocol.txt\n",
    "\n",
    "trial_metadata.to_csv(\"asvspoof2024_eval_protocol.txt\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36de325",
   "metadata": {},
   "source": [
    "# Fake or real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798110b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_metadata = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/fake_or_real_prot.txt\", sep=\" \", header=None)\n",
    "\n",
    "# update colums\n",
    "trial_metadata.columns = [\"utt\", \"subset\", \"label\"]\n",
    "trial_metadata['subset'] = 'eval'\n",
    "\n",
    "# export to protocol.txt\n",
    "trial_metadata.to_csv(\"fake_or_real_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556096cf",
   "metadata": {},
   "source": [
    "# Codec fale Yuankun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed46a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol file created at: /nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/protocol.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of all codec dataset files\n",
    "codec_files = {\n",
    "    'A1': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/A1.txt',\n",
    "    'A2': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/A2.txt',\n",
    "    'A3': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/A3.txt',\n",
    "    'C1': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C1.txt',\n",
    "    'C2': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C2.txt',\n",
    "    'C3': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C3.txt',\n",
    "    'C4': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C4.txt',\n",
    "    'C5': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C5.txt',\n",
    "    'C6': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C6.txt',\n",
    "    'C7': '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/label/C7.txt'\n",
    "}\n",
    "\n",
    "# Output protocol file path\n",
    "output_file = '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/Codecfake_Yuankun/protocol.txt'\n",
    "\n",
    "# Initialize an empty list to store protocol lines\n",
    "protocol_lines = []\n",
    "\n",
    "# Process each codec file\n",
    "for codec, file_path in codec_files.items():\n",
    "    # Read the dataset\n",
    "    df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "    \n",
    "    # Assuming columns: 0 (filename), 1 (label), 2 (subset identifier)\n",
    "    for _, row in df.iterrows():\n",
    "        filename = row[0]  # e.g., L1_p275_117.wav\n",
    "        label = 'bonafide' if row[1] == 'real' else 'spoof'  # Convert real->bonafide, fake->spoof\n",
    "        subset = 'eval'  # Fixed subset as per requirement\n",
    "        \n",
    "        # Create protocol line: <codec_folder>/<filename> <subset> <label>\n",
    "        protocol_line = f\"{codec}/{filename} {subset} {label}\"\n",
    "        protocol_lines.append(protocol_line)\n",
    "\n",
    "# Write to protocol file\n",
    "with open(output_file, 'w') as f:\n",
    "    for line in protocol_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"Protocol file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224be335",
   "metadata": {},
   "source": [
    "# SONAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe51538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol file created at: /nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/SONAR_dataset/protocol.txt\n"
     ]
    }
   ],
   "source": [
    "# List of folders\n",
    "folders = [\n",
    "    'AudioGen',\n",
    "    'FlashSpeech',\n",
    "    'NaturalSpeech3',\n",
    "    'OpenAI',\n",
    "    'PromptTTS2',\n",
    "    'SeedTTS',\n",
    "    'VALLE',\n",
    "    'VoiceBox',\n",
    "    'xTTS',\n",
    "    'real_samples'\n",
    "]\n",
    "# Base directory containing the folders (adjust this path as needed)\n",
    "base_dir = '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/SONAR_dataset'\n",
    "\n",
    "# Output protocol file path\n",
    "output_file = '/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/SONAR_dataset/protocol.txt'\n",
    "\n",
    "# Initialize an empty list to store protocol lines\n",
    "protocol_lines = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Warning: Folder {folder_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Determine label based on folder\n",
    "    label = 'bonafide' if folder == 'real_samples' else 'spoof'\n",
    "    subset = 'eval'  # Fixed subset as per requirement\n",
    "    \n",
    "    # Iterate through files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Ensure it's a file (not a directory)\n",
    "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "            # Create protocol line: <folder_name>/<file_name> <subset> <label>\n",
    "            protocol_line = f\"{folder}/{file_name} {subset} {label}\"\n",
    "            protocol_lines.append(protocol_line)\n",
    "\n",
    "# Write to protocol file\n",
    "with open(output_file, 'w') as f:\n",
    "    for line in protocol_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"Protocol file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1631cb",
   "metadata": {},
   "source": [
    "# DFADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcefbe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol file created at: DFADD_protocol.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "ROOT_FOLDER = \"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/DFADD\"\n",
    "fake_dataset_list = [\n",
    "    \"DATASET_GradTTS\",\n",
    "    \"DATASET_MatchaTTS\",\n",
    "    \"DATASET_NaturalSpeech2\",\n",
    "    \"DATASET_PflowTTS\",\n",
    "    \"DATASET_StyleTTS2\",\n",
    "]\n",
    "bonafide_dataset = \"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/DFADD/home/isjwdu/Work/Dataset/DFADD/DATASET_VCTK_BONAFIDE/test\"\n",
    "output_file = \"DFADD_protocol.txt\"\n",
    "\n",
    "# Initialize list to store protocol lines\n",
    "protocol_lines = []\n",
    "\n",
    "# Process fake datasets\n",
    "for dataset in fake_dataset_list:\n",
    "    # Construct path to test.txt\n",
    "    test_file_path = os.path.join(ROOT_FOLDER, dataset, \"test.txt\")\n",
    "    \n",
    "    # Check if test.txt exists\n",
    "    if not os.path.isfile(test_file_path):\n",
    "        print(f\"Warning: {test_file_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Read test.txt (assuming space-separated, columns: speaker_id, utt_id, _, _, label)\n",
    "    df = pd.read_csv(test_file_path, sep=\" \", header=None)\n",
    "    \n",
    "    # Process each row\n",
    "    for _, row in df.iterrows():\n",
    "        utt_id = row[1]  # e.g., p227_093\n",
    "        # Skip bonafide entries\n",
    "        current_label = row[4]\n",
    "        if current_label == \"bonafide\":\n",
    "            continue\n",
    "        \n",
    "        label = 'spoof'  # All entries in fake datasets are spoof\n",
    "        subset = 'eval'  # Fixed subset as per requirement\n",
    "        \n",
    "        # Construct relative path: <dataset>/<utt_id>.wav\n",
    "        relative_path = f\"{dataset}/test/{utt_id}.flac\"\n",
    "        \n",
    "        # Create protocol line\n",
    "        protocol_line = f\"{relative_path} {subset} {label}\"\n",
    "        protocol_lines.append(protocol_line)\n",
    "\n",
    "# Process bonafide dataset\n",
    "if os.path.isdir(bonafide_dataset):\n",
    "    # Get relative path for bonafide dataset\n",
    "    bonafide_folder = os.path.relpath(bonafide_dataset, ROOT_FOLDER)\n",
    "    \n",
    "    # Iterate through .wav files in bonafide_dataset\n",
    "    for file_name in os.listdir(bonafide_dataset):\n",
    "        if file_name.endswith('.wav'):\n",
    "            label = 'bonafide'  # All files in bonafide_dataset are bonafide\n",
    "            subset = 'eval'  # Fixed subset\n",
    "            \n",
    "            # Construct relative path: <bonafide_folder>/<file_name>\n",
    "            relative_path = f\"{bonafide_folder}/{file_name}\"\n",
    "            \n",
    "            # Create protocol line\n",
    "            protocol_line = f\"{relative_path} {subset} {label}\"\n",
    "            protocol_lines.append(protocol_line)\n",
    "else:\n",
    "    print(f\"Warning: Bonafide dataset directory {bonafide_dataset} does not exist.\")\n",
    "\n",
    "# Write to protocol file\n",
    "with open(output_file, 'w') as f:\n",
    "    for line in protocol_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"Protocol file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be337ec",
   "metadata": {},
   "source": [
    "# LibriSeVoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc82e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol file created at: LibriSeVoc_protocol.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_folders = os.listdir(\"/nvme1/hungdx/Datasets/LibriSeVoc\")\n",
    "list_of_folders\n",
    "\n",
    "\n",
    "base_dir = \"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/LibriSeVoc\"  # Adjust this path as needed\n",
    "output_file = \"LibriSeVoc_protocol.txt\"\n",
    "\n",
    "# Initialize list to store protocol lines\n",
    "protocol_lines = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in list_of_folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Warning: Folder {folder_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Determine label based on folder\n",
    "    label = 'bonafide' if folder == 'gt' else 'spoof'\n",
    "    subset = 'eval'  # Fixed subset as per requirement\n",
    "    \n",
    "    # Iterate through .wav files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Construct relative path: <folder>/<file_name>\n",
    "            relative_path = f\"{folder}/{file_name}\"\n",
    "            \n",
    "            # Create protocol line: <relative_path> <subset> <label>\n",
    "            protocol_line = f\"{relative_path} {subset} {label}\"\n",
    "            protocol_lines.append(protocol_line)\n",
    "\n",
    "# Write to protocol file\n",
    "with open(output_file, 'w') as f:\n",
    "    for line in protocol_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"Protocol file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854914f",
   "metadata": {},
   "source": [
    "# ADD_2022 track 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87a519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(\"/nvme2/hungdx/Datasets/track1_label.txt\", sep=\" \", header=None)\n",
    "df.columns = [\"utt\", \"label\"]\n",
    "\n",
    "# change label to bonafide and spoof\n",
    "df['label'] = df['label'].replace({'genuine': 'bonafide', 'fake': 'spoof'})\n",
    "\n",
    "df['subset'] = 'eval'\n",
    "\n",
    "# change order of columns\n",
    "df = df[['utt', 'subset', 'label']]\n",
    "\n",
    "# convert relative path to absolute path\n",
    "# df['utt'] = df['utt'].apply(lambda x: os.path.join(\"wav/\", x))\n",
    "# df\n",
    "# export to protocol.txt\n",
    "df.to_csv(\"ADD2022_track1_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5ef6c",
   "metadata": {},
   "source": [
    "# ADD_2022 track 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a02753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(\"/nvme2/hungdx/Datasets/track3_R2_label.txt\", sep=\" \", header=None)\n",
    "df.columns = [\"utt\", \"label\", \"unknown\"]\n",
    "\n",
    "# change label to bonafide and spoof\n",
    "df['label'] = df['label'].replace({'genuine': 'bonafide', 'fake': 'spoof'})\n",
    "\n",
    "df['subset'] = 'eval'\n",
    "\n",
    "# change order of columns\n",
    "df = df[['utt', 'subset', 'label']]\n",
    "\n",
    "# convert relative path to absolute path\n",
    "# df['utt'] = df['utt'].apply(lambda x: os.path.join(\"wav/\", x))\n",
    "# df\n",
    "# export to protocol.txt\n",
    "df.to_csv(\"ADD2022_track3_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360f046",
   "metadata": {},
   "source": [
    "# ADD 2023 R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b2bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/ADD2023_R1/label.txt\", sep=\" \", header=None)\n",
    "df.columns = [\"utt\", \"label\"]\n",
    "\n",
    "# change label to bonafide and spoof\n",
    "df['label'] = df['label'].replace({'genuine': 'bonafide', 'fake': 'spoof'})\n",
    "\n",
    "df['subset'] = 'eval'\n",
    "\n",
    "# change order of columns\n",
    "df = df[['utt', 'subset', 'label']]\n",
    "\n",
    "# convert relative path to absolute path\n",
    "df['utt'] = df['utt'].apply(lambda x: os.path.join(\"wav/\", x))\n",
    "df\n",
    "# export to protocol.txt\n",
    "df.to_csv(\"ADD2023_R1_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbf72a",
   "metadata": {},
   "source": [
    "# ADD 2023 R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv(\"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena/ADD2023_R2/label.txt\", sep=\" \", header=None)\n",
    "df.columns = [\"utt\", \"label\"]\n",
    "\n",
    "# change label to bonafide and spoof\n",
    "df['label'] = df['label'].replace({'genuine': 'bonafide', 'fake': 'spoof'})\n",
    "\n",
    "df['subset'] = 'eval'\n",
    "\n",
    "# change order of columns\n",
    "df = df[['utt', 'subset', 'label']]\n",
    "\n",
    "# convert relative path to absolute path\n",
    "df['utt'] = df['utt'].apply(lambda x: os.path.join(\"wav/\", x))\n",
    "df\n",
    "# export to protocol.txt\n",
    "df.to_csv(\"ADD2023_R2_protocol.txt\", sep=\" \", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acf5b",
   "metadata": {},
   "source": [
    "# Verify all folders in benchrmark have protocol.txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c08acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BENCHMARK_ROOT = \"/nvme1/hungdx/Lightning-hydra/data/huggingface_benchrmark_Speech-DF-Arena\"\n",
    "list_of_folders = os.listdir(BENCHMARK_ROOT)\n",
    "\n",
    "# only keep folders\n",
    " \n",
    "list_of_folders =  [folder for folder in list_of_folders if os.path.isdir(os.path.join(BENCHMARK_ROOT, folder))]\n",
    "\n",
    "for folder in list_of_folders:\n",
    "    # check if folder have protocol.txt\n",
    "    if not os.path.isfile(os.path.join(BENCHMARK_ROOT, folder, \"protocol.txt\")):\n",
    "        print(f\"{folder} do not have protocol.txt\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
