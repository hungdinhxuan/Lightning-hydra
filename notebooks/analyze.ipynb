{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:   0%|          | 0/31779 [00:00<?, ?it/s]/tmp/ipykernel_3393222/3850030267.py:28: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duration = librosa.get_duration(filename=audio_path)\n",
      "Processing audio files: 100%|██████████| 31779/31779 [02:46<00:00, 190.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to in_the_wild_durations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_audio_durations(audio_folder, output_csv):\n",
    "    \"\"\"\n",
    "    Calculate duration of each audio file in the folder and write results to CSV\n",
    "    \n",
    "    Parameters:\n",
    "        audio_folder (str): Path to folder containing audio files\n",
    "        output_csv (str): Path to output CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of audio files\n",
    "    audio_files = [f for f in os.listdir(audio_folder) if f.endswith(('.wav', '.mp3', '.flac'))]\n",
    "    \n",
    "    # Open CSV file to write results\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['filename', 'duration'])  # Write header\n",
    "        \n",
    "        # Process each audio file with progress bar\n",
    "        for audio_file in tqdm(audio_files, desc=\"Processing audio files\"):\n",
    "            try:\n",
    "                # Load audio file and get duration\n",
    "                audio_path = os.path.join(audio_folder, audio_file)\n",
    "                duration = librosa.get_duration(filename=audio_path)\n",
    "                \n",
    "                # Write result to CSV\n",
    "                writer.writerow([audio_file, f\"{duration:.2f}\"])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audio_file}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    audio_folder = \"/data/hungdx/Lightning-hydra/data/in_the_wild\"\n",
    "    output_csv = \"in_the_wild_durations.csv\"\n",
    "    \n",
    "    get_audio_durations(audio_folder, output_csv)\n",
    "    print(f\"Results written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average duration:  4.287989552849366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('in_the_wild_durations.csv')\n",
    "\n",
    "print(\"Average duration: \", df['duration'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NaN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/data/hungdx/Lightning-hydra/src')\n",
    "\n",
    "from data.normal_multiview_datamodule import Dataset_for_dev\n",
    "\n",
    "\n",
    "def genList(protocol_path, is_train=False, is_eval=False, is_dev=False):\n",
    "    \"\"\"\n",
    "            This function generates the list of files and their corresponding labels\n",
    "            Specifically for the standard CNSL dataset\n",
    "        \"\"\"\n",
    "     # bonafide: 1, spoof: 0\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "\n",
    "    if (is_train):\n",
    "        with open(protocol_path, 'r') as f:\n",
    "            l_meta = f.readlines()\n",
    "        for line in l_meta:\n",
    "            utt, subset, label = line.strip().split()\n",
    "            if subset == 'train':\n",
    "                file_list.append(utt)\n",
    "                d_meta[utt] = 1 if label == 'bonafide' else 0\n",
    "\n",
    "        return d_meta, file_list\n",
    "    if (is_dev):\n",
    "        with open(protocol_path, 'r') as f:\n",
    "            l_meta = f.readlines()\n",
    "        for line in l_meta:\n",
    "            utt, subset, label = line.strip().split()\n",
    "            if subset == 'dev':\n",
    "                file_list.append(utt)\n",
    "                d_meta[utt] = 1 if label == 'bonafide' else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    if (is_eval):\n",
    "        # no eval protocol_path yet\n",
    "        with open(protocol_path, 'r') as f:\n",
    "            l_meta = f.readlines()\n",
    "        for line in l_meta:\n",
    "            utt, subset, label = line.strip().split()\n",
    "            if subset == 'eval':\n",
    "                file_list.append(utt)\n",
    "                d_meta[utt] = 1 if label == 'bonafide' else 0\n",
    "        # return d_meta, file_list\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    augmentation_methods: List[str]\n",
    "    wav_samp_rate: int\n",
    "    online_aug: bool\n",
    "    aug_dir: str\n",
    "    noise_path: str\n",
    "    rir_path: str\n",
    "    repeat_pad: bool\n",
    "    random_start: bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    views: List[int]\n",
    "    protocol_path: str\n",
    "    nBands: int\n",
    "    minF: int\n",
    "    maxF: int\n",
    "    minBW: int\n",
    "    maxBW: int\n",
    "    minCoeff: int\n",
    "    maxCoeff: int\n",
    "    minG: int\n",
    "    maxG: int\n",
    "    minBiasLinNonLin: int\n",
    "    maxBiasLinNonLin: int\n",
    "    N_f: int\n",
    "    P: int\n",
    "    g_sd: int\n",
    "    SNRmin: int\n",
    "    SNRmax: int\n",
    "    data: DataConfig\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key == 'data':\n",
    "            return asdict(self.data)\n",
    "        return asdict(self)[key]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, config_dict: dict):\n",
    "        data_config = DataConfig(**config_dict['data'])\n",
    "        config_dict['data'] = data_config\n",
    "        return cls(**config_dict)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "config_dict = {\n",
    "    'views': [1, 2, 3, 4],\n",
    "    'protocol_path': '${oc.env:LARGE_CORPUS_FOR_CNSL_PROTOCOLS}',\n",
    "    'nBands': 5,\n",
    "    'minF': 20,\n",
    "    'maxF': 8000,\n",
    "    'minBW': 100,\n",
    "    'maxBW': 1000,\n",
    "    'minCoeff': 10,\n",
    "    'maxCoeff': 100,\n",
    "    'minG': 0,\n",
    "    'maxG': 0,\n",
    "    'minBiasLinNonLin': 5,\n",
    "    'maxBiasLinNonLin': 20,\n",
    "    'N_f': 5,\n",
    "    'P': 10,\n",
    "    'g_sd': 2,\n",
    "    'SNRmin': 10,\n",
    "    'SNRmax': 40,\n",
    "    'data': {\n",
    "        'augmentation_methods': [\"RawBoost12\", \"pitch_1\", \"volume_10\", \"speed_01\", \"none\"],\n",
    "        'wav_samp_rate': 16000,\n",
    "        'online_aug': True,\n",
    "        'aug_dir': '${oc.env:LARGE_CORPUS_FOR_CNSL}/aug',\n",
    "        'noise_path': '${oc.env:NOISE_PATH}',\n",
    "        'rir_path': '${oc.env:RIR_PATH}',\n",
    "        'repeat_pad': True,\n",
    "        'random_start': True\n",
    "    }\n",
    "}\n",
    "# Create Args object\n",
    "args = Args.from_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocoders: []\n"
     ]
    }
   ],
   "source": [
    "protocol_path = \"/data/hungdx/Lightning-hydra/notebooks/new_protocol_trim_vocoded_cleaned.txt\"\n",
    "data_dir = \"/data/hungdx/Lightning-hydra/data/0_large-corpus\"\n",
    "\n",
    "d_label_dev, file_dev = genList(protocol_path,\n",
    "    is_train=False, is_eval=False, is_dev=True)\n",
    "\n",
    "data_val = Dataset_for_dev(args, list_IDs=file_dev, labels=d_label_dev,\n",
    "                       base_dir=data_dir+'/',  is_train=False, **args['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data.components.collate_fn import multi_view_collate_fn, variable_multi_view_collate_fn\n",
    "\n",
    "\n",
    "def collate_fn(x): return multi_view_collate_fn(\n",
    "    x,\n",
    "    args.views,\n",
    "    args.data.wav_samp_rate,\n",
    "    \"repeat\",\n",
    "    True\n",
    ")\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    dataset=data_val,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 66725/66725 [08:32<00:00, 130.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate through the DataLoader with a progress bar\n",
    "for batch_idx, batch in enumerate(tqdm(dev_dataloader, desc=\"Validating\")):\n",
    "    for view, (x, y) in batch.items():\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            print(\"Found NaN or Inf in validation inputs!\")\n",
    "        if torch.isnan(y).any() or torch.isinf(y).any():\n",
    "            print(\"Found NaN or Inf in validation labels!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asvspoof5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
